{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This a makey-upey neural network with 1 layer of 5 neurons which is the output layer.\n",
    "Each input has 4 values and is associated with desired output with 5 values. All this requires a 5 by 4 weight matrix.\n",
    "16 sample inputs and corresponding desired outputs are provided.\n",
    "\n",
    "Yout task is to write code for feedforward() and getCost().\n",
    "\n",
    "Then you are finally asked to add another layer to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigm(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))  # Sigmoid function: Maps any input to a value between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [0 0 1 1]\n",
      " [0 1 0 0]\n",
      " [0 1 0 1]\n",
      " [0 1 1 0]\n",
      " [0 1 1 1]\n",
      " [1 0 0 0]\n",
      " [1 0 0 1]\n",
      " [1 0 1 0]\n",
      " [1 0 1 1]\n",
      " [1 1 0 0]\n",
      " [1 1 0 1]\n",
      " [1 1 1 0]\n",
      " [1 1 1 1]] \n",
      "\n",
      "(16, 4) \n",
      "\n",
      "[[1 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 0 1 0 0]\n",
      " [0 1 0 0 0]] \n",
      "\n",
      "(16, 5)\n"
     ]
    }
   ],
   "source": [
    "# Input data (16 samples with 4 values each)\n",
    "inputs = np.array([[0,0,0,0],[0,0,0,1],[0,0,1,0],[0,0,1,1],\n",
    "                   [0,1,0,0],[0,1,0,1],[0,1,1,0],[0,1,1,1],\n",
    "                   [1,0,0,0],[1,0,0,1],[1,0,1,0],[1,0,1,1],\n",
    "                   [1,1,0,0],[1,1,0,1],[1,1,1,0],[1,1,1,1]])\n",
    "\n",
    "# Desired output (5 values per input)\n",
    "targets = np.array([[1,0,0,0,0],[1,0,0,0,0],[0,1,0,0,0],[0,1,0,0,0],\n",
    "                    [0,0,1,0,0],[0,0,1,0,0],[0,1,0,0,0],[0,0,1,0,0],\n",
    "                    [0,0,1,0,0],[0,0,1,0,0],[0,0,0,1,0],[0,0,0,1,0],\n",
    "                    [0,0,0,0,1],[0,0,0,1,0],[0,0,1,0,0],[0,1,0,0,0]])\n",
    "\n",
    "print(inputs, '\\n')\n",
    "print(inputs.shape, '\\n')\n",
    "print(targets, '\\n')\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network with 4 inputs and 5 outputs (one hidden layer)\n",
    "class NN(object):\n",
    "    def __init__(self):\n",
    "        np.random.seed(2021)  # Seed for reproducibility\n",
    "        self.w = np.random.randn(5, 4)  # Weights matrix with 5 rows and 4 cols (4 inputs, 5 neurons)\n",
    "        self.b = np.random.randn(5, 1)  # 5-item column vector containing biases for the output layer\n",
    "    \n",
    "    def feedforward(self, x):\n",
    "        # Input layer to output layer\n",
    "        z_hidden = np.dot(self.w, x.reshape(4, 1)) + self.b  # Weighted sum of inputs + biases\n",
    "        a_hidden = sigm(z_hidden)  # Apply sigmoid activation function\n",
    "        return a_hidden  # Return output of the layer\n",
    "    \n",
    "    def getCost(self, xs, ys):\n",
    "        cost = 0.0\n",
    "        # Loop through each sample in the dataset\n",
    "        for i in range(len(xs)):\n",
    "            x = xs[i].reshape(4, 1)  # Reshape input to column vector (4, 1)\n",
    "            y = ys[i].reshape(5, 1)  # Reshape target to column vector (5, 1)\n",
    "\n",
    "            # Forward pass\n",
    "            a_hidden = self.feedforward(x)\n",
    "\n",
    "            # Calculate cost using Mean Squared Error (MSE)\n",
    "            cost += np.sum((a_hidden - y) ** 2)\n",
    "        \n",
    "        return cost / 16.0  # Return average MSE cost over all 16 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.48860905  0.67601087 -0.41845137 -0.80652081]\n",
      " [ 0.55587583 -0.70550429  1.13085826  0.64500184]\n",
      " [ 0.10641374  0.42215483  0.12420684 -0.83795346]\n",
      " [ 0.4090157   0.10275122 -1.90772239  1.1002243 ]\n",
      " [-1.40232506 -0.22508127 -1.33620597  0.30372151]] \n",
      "\n",
      "[[-0.72015884]\n",
      " [ 2.5449146 ]\n",
      " [ 1.31729112]\n",
      " [ 0.0726303 ]\n",
      " [-0.25610814]]\n"
     ]
    }
   ],
   "source": [
    "# Create the neural network and check weights and biases\n",
    "nn = NN()\n",
    "print(nn.w, '\\n')\n",
    "print(nn.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.32735801]\n",
      " [0.92723113]\n",
      " [0.78873067]\n",
      " [0.5181496 ]\n",
      " [0.43632065]]\n"
     ]
    }
   ],
   "source": [
    "# Test feedforward on first input vector\n",
    "# The input vector (shape 4,) must first be reshaped to a column vector (shape 4,1)\n",
    "print(nn.feedforward(inputs[0].reshape(4, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7771013151641077\n"
     ]
    }
   ],
   "source": [
    "# Compute average MSE cost over all input vectors\n",
    "print(nn.getCost(inputs, targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Copy the above NN class definition and pasted it to a new cell, renaming the class to NN2. Then add a layer of six hidden neurons to it. Modify code in NN2 so that feedforward() and getCost() work on this new architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network with 4 inputs, 5 outputs, and two hidden layers\n",
    "class NN2(object):\n",
    "    def __init__(self):\n",
    "        np.random.seed(2021)  # Seed for reproducibility\n",
    "        # Initialize weights and biases for the two layers\n",
    "        self.w1 = np.random.randn(5, 4)  # Weights matrix for the first hidden layer (5 neurons, 4 inputs)\n",
    "        self.b1 = np.random.randn(5, 1)  # Biases for the first hidden layer (5 biases)\n",
    "        \n",
    "        self.w2 = np.random.randn(5, 5)  # Weights matrix for the second hidden layer (5 neurons, 5 neurons from layer 1)\n",
    "        self.b2 = np.random.randn(5, 1)  # Biases for the second hidden layer (5 biases)\n",
    "\n",
    "    def feedforward(self, x):\n",
    "        # Input layer to hidden layer 1\n",
    "        z_hidden1 = np.dot(self.w1, x.reshape(4, 1)) + self.b1  # Weighted sum for layer 1\n",
    "        a_hidden1 = sigm(z_hidden1)  # Apply sigmoid activation for layer 1\n",
    "        \n",
    "        # Hidden layer 1 to hidden layer 2\n",
    "        z_hidden2 = np.dot(self.w2, a_hidden1) + self.b2  # Weighted sum for layer 2\n",
    "        a_hidden2 = sigm(z_hidden2)  # Apply sigmoid activation for layer 2\n",
    "\n",
    "        # Return output of second hidden layer (final activations for now)\n",
    "        return a_hidden2\n",
    "    \n",
    "    def getCost(self, xs, ys):\n",
    "        cost = 0.0\n",
    "        # Loop through each sample in the dataset\n",
    "        for i in range(len(xs)):\n",
    "            x = xs[i].reshape(4, 1)  # Reshape input to column vector (4, 1)\n",
    "            y = ys[i].reshape(5, 1)  # Reshape target to column vector (5, 1)\n",
    "\n",
    "            # Forward pass\n",
    "            a_hidden = self.feedforward(x)\n",
    "\n",
    "            # Calculate cost using Mean Squared Error (MSE)\n",
    "            cost += np.sum((a_hidden - y) ** 2)\n",
    "        \n",
    "        return cost / 16.0  # Return average MSE cost over all 16 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.48860905  0.67601087 -0.41845137 -0.80652081]\n",
      " [ 0.55587583 -0.70550429  1.13085826  0.64500184]\n",
      " [ 0.10641374  0.42215483  0.12420684 -0.83795346]\n",
      " [ 0.4090157   0.10275122 -1.90772239  1.1002243 ]\n",
      " [-1.40232506 -0.22508127 -1.33620597  0.30372151]] \n",
      "\n",
      "[[-0.72015884]\n",
      " [ 2.5449146 ]\n",
      " [ 1.31729112]\n",
      " [ 0.0726303 ]\n",
      " [-0.25610814]]\n",
      "[[ 0.13801041  1.14723599  1.37626076 -0.47218397  0.5240849 ]\n",
      " [ 1.48510793  1.48243225  0.72813051 -0.38964808  0.27889376]\n",
      " [ 0.0519002  -1.04474368 -0.16150753 -2.79353057  0.36164801]\n",
      " [ 0.24010758  0.47781228  0.20885194  0.91791163 -1.41177784]\n",
      " [ 1.22423572 -0.54565772  0.90674805 -0.98261724 -0.63316189]] \n",
      "\n",
      "[[ 0.82552024]\n",
      " [-1.28449686]\n",
      " [-0.34730878]\n",
      " [-1.07776075]\n",
      " [ 0.97257495]]\n"
     ]
    }
   ],
   "source": [
    "# Create NN2 (two hidden layers) and check feedforward and cost calculation\n",
    "nn2 = NN2()\n",
    "print(nn2.w1, '\\n')\n",
    "print(nn2.b1)\n",
    "print(nn2.w2, '\\n')\n",
    "print(nn2.b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.93762534]\n",
      " [0.79484326]\n",
      " [0.02358345]\n",
      " [0.55513918]\n",
      " [0.72712863]]\n",
      "2.3073609747898476\n"
     ]
    }
   ],
   "source": [
    "# Test feedforward on a new input vector\n",
    "print(nn2.feedforward(np.array([1, 1, 0, 1]).reshape(4, 1)))\n",
    "\n",
    "# Compute average MSE cost over all input vectors\n",
    "print(nn2.getCost(inputs, targets))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
